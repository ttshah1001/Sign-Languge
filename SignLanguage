import cv2
import mediapipe as mp
import numpy as np
import pickle
import os
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import time
from collections import Counter

class SignLanguageDetector:
    def __init__(self):
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=1,
            min_detection_confidence=0.7,
            min_tracking_confidence=0.5
        )
        self.mp_drawing = mp.solutions.drawing_utils
        
        self.labels_dict = {
            0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 
            9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 
            17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'
        }
        
        self.letter_to_num = {v: k for k, v in self.labels_dict.items()}
        
        self.model = None
        self.prediction_history = []
        self.history_size = 8
        
    def extract_hand_landmarks(self, image):
        """Extract normalized hand landmarks from image"""
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = self.hands.process(rgb_image)
        
        if results.multi_hand_landmarks:
            hand_landmarks = results.multi_hand_landmarks[0]
            
            landmarks = []
            x_coords = []
            y_coords = []
            
            # collect coordinates
            for landmark in hand_landmarks.landmark:
                x_coords.append(landmark.x)
                y_coords.append(landmark.y)
            
            #use wrist to mark
            wrist_x, wrist_y = x_coords[0], y_coords[0]
            
            for i in range(len(x_coords)):
                normalized_x = x_coords[i] - wrist_x
                normalized_y = y_coords[i] - wrist_y
                landmarks.extend([normalized_x, normalized_y])
            
            return np.array(landmarks)
        
        return None
    
    def collect_data(self):
        """Collect training data for all 26 letters"""
        cap = cv2.VideoCapture(0)
        
        print("Sign Language Data Collection - All 26 Letters")
        print("Instructions:")
        print("- Press any letter key (A-Z) to collect data")
        print("- Collect 30+ samples per letter for best results")
        print("- Press 'q' to quit, 's' to start training")
        print("- Press 'r' to see statistics")
        
        data = []
        labels = []
        collection_count = {letter: 0 for letter in self.labels_dict.values()}
        
        current_letter_display = None
        last_collection_time = 0
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame = cv2.flip(frame, 1)
            landmarks = self.extract_hand_landmarks(frame)
            
            # draw hand
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = self.hands.process(rgb_frame)
            
            if results.multi_hand_landmarks:
                for hand_landmarks in results.multi_hand_landmarks:
                    self.mp_drawing.draw_landmarks(
                        frame, hand_landmarks, self.mp_hands.HAND_CONNECTIONS)
                cv2.rectangle(frame, (5, 5), (frame.shape[1]-5, frame.shape[0]-5), (0, 255, 0), 3)
            else:
                cv2.rectangle(frame, (5, 5), (frame.shape[1]-5, frame.shape[0]-5), (0, 0, 255), 3)
            
            # instructions
            cv2.putText(frame, 'Press letter keys (A-Z) to collect data', 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
            cv2.putText(frame, 'Q: quit  S: train  R: stats', 
                       (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
            cv2.putText(frame, f'Total samples: {len(data)}', 
                       (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
            
            # collection
            if current_letter_display and time.time() - last_collection_time < 2:
                cv2.putText(frame, f'Collected: {current_letter_display}', 
                           (frame.shape[1]//2 - 100, frame.shape[0]//2), 
                           cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 3)
            
            # collection so far
            y_offset = 110
            sorted_letters = sorted(collection_count.items(), key=lambda x: x[1], reverse=True)
            for i, (letter, count) in enumerate(sorted_letters[:10]):
                cv2.putText(frame, f'{letter}: {count}', 
                           (10, y_offset + i*20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
            
            cv2.imshow('Sign Language Data Collection', frame)
            
            key = cv2.waitKey(1) & 0xFF
            
            # letter input
            if key >= ord('a') and key <= ord('z'):
                letter = chr(key).upper()
            elif key >= ord('A') and key <= ord('Z'):
                letter = chr(key).upper()
            else:
                letter = None
            
            if letter and landmarks is not None:
                label_num = self.letter_to_num[letter]
                data.append(landmarks)
                labels.append(label_num)
                collection_count[letter] += 1
                current_letter_display = letter
                last_collection_time = time.time()
                print(f"Collected {letter}: {collection_count[letter]} samples")
            
            elif key == ord('q') or key == ord('Q'):
                break
            elif key == ord('s') or key == ord('S'):
                if len(data) >= 100:
                    print("Starting training...")
                    self.train_model(np.array(data), np.array(labels))
                    break
                else:
                    print(f"Need at least 100 samples total. Current: {len(data)}")
            elif key == ord('r') or key == ord('R'):
                self.show_statistics(collection_count)
        
        cap.release()
        cv2.destroyAllWindows()
    
    def show_statistics(self, collection_count):
        """Show collection statistics"""
        print("\n=== Collection Statistics ===")
        total = sum(collection_count.values())
        print(f"Total samples: {total}")
        print("Per letter breakdown:")
        
        for letter in self.labels_dict.values():
            count = collection_count[letter]
            status = "✓" if count >= 30 else "!" if count >= 15 else "✗"
            print(f"{letter}: {count:2d} {status}")
        
        print("✓ = Excellent (30+), ! = Good (15+), ✗ = Need more")
        print("=============================\n")
    
    def train_model(self, X, y):
        """Train the model using Random Forest"""
        if len(X) < 100:
            print("Need at least 100 samples total.")
            return
        
        print(f"Training with {len(X)} samples...")
        print(f"Classes: {len(np.unique(y))}")
        

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # train model
        self.model = RandomForestClassifier(
            n_estimators=300,
            max_depth=20,
            min_samples_split=3,
            min_samples_leaf=1,
            random_state=42,
            n_jobs=-1
        )
        
        self.model.fit(X_train, y_train)
        
        # test
        y_pred = self.model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print(f"Accuracy: {accuracy:.3f}")
        
        # save model
        model_data = {
            'model': self.model,
            'labels_dict': self.labels_dict
        }
        with open('sign_model_26letters.pkl', 'wb') as f:
            pickle.dump(model_data, f)
        print("Model saved!")
    
    def load_model(self, model_path='sign_model_26letters.pkl'):
        """Load trained model"""
        try:
            with open(model_path, 'rb') as f:
                model_data = pickle.load(f)
            self.model = model_data['model']
            self.labels_dict = model_data['labels_dict']
            print(f"Model loaded! Supports: {list(self.labels_dict.values())}")
            return True
        except FileNotFoundError:
            print("Model file not found.")
            return False
        except Exception as e:
            print(f"Error loading model: {e}")
            return False
    
    def smooth_predictions(self, prediction):
        """Smooth predictions to reduce jitter"""
        self.prediction_history.append(prediction)
        
        if len(self.prediction_history) > self.history_size:
            self.prediction_history.pop(0)
        
        if len(self.prediction_history) >= 5:
            return Counter(self.prediction_history).most_common(1)[0][0]
        return prediction
    
    def detect_realtime(self):
        """Real-time detection for all 26 letters"""
        if self.model is None:
            print("No model loaded!")
            return
        
        cap = cv2.VideoCapture(0)
        
        print("Real-time Detection - All 26 Letters")
        print("Controls: Q=quit, C=clear sentence, SPACE=add space")
        
        sentence = ""
        last_prediction = None
        stable_count = 0
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame = cv2.flip(frame, 1)
            landmarks = self.extract_hand_landmarks(frame)
            
           
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = self.hands.process(rgb_frame)
            
            if results.multi_hand_landmarks:
                for hand_landmarks in results.multi_hand_landmarks:
                    self.mp_drawing.draw_landmarks(
                        frame, hand_landmarks, self.mp_hands.HAND_CONNECTIONS)
                cv2.rectangle(frame, (5, 5), (frame.shape[1]-5, frame.shape[0]-5), (0, 255, 0), 2)
            else:
                cv2.rectangle(frame, (5, 5), (frame.shape[1]-5, frame.shape[0]-5), (0, 0, 255), 2)
            
            # prediction
            if landmarks is not None:
                prediction = self.model.predict([landmarks])[0]
                smooth_prediction = self.smooth_predictions(prediction)
                predicted_letter = self.labels_dict.get(smooth_prediction, 'Unknown')
                
                cv2.putText(frame, f'Letter: {predicted_letter}', 
                           (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 0, 0), 4)
                

                
                last_prediction = predicted_letter
                
            else:
                cv2.putText(frame, 'Show your hand', 
                           (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 3)
                stable_count = 0
                last_prediction = None
            
            
            # instructions
            cv2.putText(frame, 'Q: quit', 
                       (50, frame.shape[0] - 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)
            
            cv2.imshow('Sign Language Detection - 26 Letters', frame)
            
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q') or key == ord('Q'):
                break
        
        cap.release()
        cv2.destroyAllWindows()

def main():
    detector = SignLanguageDetector()
    
    print("Sign Language Detection - All 26 Letters")
    print("Uses MediaPipe + Random Forest (No TensorFlow needed)")
    print("\n1. Collect training data")
    print("2. Load model and start detection")
    print("3. Quick test with sample data")
    
    choice = input("\nEnter choice (1/2/3): ")
    
    if choice == '1':
        print("\nTips for data collection:")
        print("- Collect 30+ samples per letter")
        print("- Use different hand angles")
        print("- Keep good lighting")
        print("- Hold signs steady")
        detector.collect_data()
        
    elif choice == '2':
        if detector.load_model():
            detector.detect_realtime()
        else:
            print("No model found. Collect data first.")
    
    elif choice == '3':
        print("Creating test data...")
        X_sample = np.random.random((650, 42)) 
        y_sample = np.repeat(range(26), 25)
        detector.train_model(X_sample, y_sample)
        detector.detect_realtime()
    
    else:
        print("Invalid choice!")

if __name__ == "__main__":
    main()